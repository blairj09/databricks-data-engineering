{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Fetch Weather Data\n\nThis notebook fetches historical weather data from the Open-Meteo API\nand loads it into a Delta table for use by the declarative pipeline."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get parameters from widgets\n",
    "dbutils.widgets.text(\"catalog\", \"hive_metastore\", \"Catalog\")\n",
    "dbutils.widgets.text(\"schema\", \"default\", \"Schema\")\n",
    "dbutils.widgets.text(\"start_date\", \"2023-01-01\", \"Start Date\")\n",
    "dbutils.widgets.text(\"end_date\", \"2023-12-31\", \"End Date\")\n",
    "\n",
    "catalog = dbutils.widgets.get(\"catalog\")\n",
    "schema = dbutils.widgets.get(\"schema\")\n",
    "start_date = dbutils.widgets.get(\"start_date\")\n",
    "end_date = dbutils.widgets.get(\"end_date\")\n",
    "\n",
    "print(f\"Catalog: {catalog}\")\n",
    "print(f\"Schema: {schema}\")\n",
    "print(f\"Date range: {start_date} to {end_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Set catalog and schema\nspark.sql(f\"USE CATALOG `{catalog}`\")\nspark.sql(f\"USE SCHEMA `{schema}`\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# NYC coordinates\n",
    "NYC_LATITUDE = 40.7128\n",
    "NYC_LONGITUDE = -74.0060\n",
    "\n",
    "# Open-Meteo Historical Weather API endpoint\n",
    "ARCHIVE_API_URL = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "\n",
    "# Weather variables to fetch\n",
    "HOURLY_VARIABLES = [\n",
    "    \"temperature_2m\",\n",
    "    \"relative_humidity_2m\",\n",
    "    \"precipitation\",\n",
    "    \"rain\",\n",
    "    \"snowfall\",\n",
    "    \"wind_speed_10m\",\n",
    "    \"weather_code\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_weather_chunk(start: str, end: str) -> pd.DataFrame:\n",
    "    \"\"\"Fetch weather data for a date range.\"\"\"\n",
    "    params = {\n",
    "        \"latitude\": NYC_LATITUDE,\n",
    "        \"longitude\": NYC_LONGITUDE,\n",
    "        \"start_date\": start,\n",
    "        \"end_date\": end,\n",
    "        \"hourly\": \",\".join(HOURLY_VARIABLES),\n",
    "        \"timezone\": \"America/New_York\",\n",
    "    }\n",
    "    \n",
    "    response = requests.get(ARCHIVE_API_URL, params=params, timeout=30)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    \n",
    "    hourly = data[\"hourly\"]\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        \"datetime\": pd.to_datetime(hourly[\"time\"]),\n",
    "        \"temperature_2m\": hourly.get(\"temperature_2m\"),\n",
    "        \"relative_humidity_2m\": hourly.get(\"relative_humidity_2m\"),\n",
    "        \"precipitation\": hourly.get(\"precipitation\"),\n",
    "        \"rain\": hourly.get(\"rain\"),\n",
    "        \"snowfall\": hourly.get(\"snowfall\"),\n",
    "        \"wind_speed_10m\": hourly.get(\"wind_speed_10m\"),\n",
    "        \"weather_code\": hourly.get(\"weather_code\"),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch weather data in chunks to avoid API timeouts\n",
    "print(f\"Fetching weather data from {start_date} to {end_date}...\")\n",
    "\n",
    "start = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "end = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "chunk_days = 30\n",
    "\n",
    "chunks = []\n",
    "current_start = start\n",
    "\n",
    "while current_start < end:\n",
    "    current_end = min(current_start + timedelta(days=chunk_days - 1), end)\n",
    "    print(f\"  Fetching {current_start.date()} to {current_end.date()}...\")\n",
    "    \n",
    "    chunk_df = fetch_weather_chunk(\n",
    "        start=current_start.strftime(\"%Y-%m-%d\"),\n",
    "        end=current_end.strftime(\"%Y-%m-%d\"),\n",
    "    )\n",
    "    chunks.append(chunk_df)\n",
    "    current_start = current_end + timedelta(days=1)\n",
    "\n",
    "weather_df = pd.concat(chunks, ignore_index=True)\n",
    "print(f\"\\nFetched {len(weather_df)} weather records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Spark DataFrame and write to Delta table\n",
    "spark_df = spark.createDataFrame(weather_df)\n",
    "\n",
    "table_name = \"weather_raw\"\n",
    "print(f\"Writing to {catalog}.{schema}.{table_name}...\")\n",
    "\n",
    "spark_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(table_name)\n",
    "\n",
    "print(f\"Successfully wrote weather data to {table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample of the data\n",
    "spark.table(table_name).show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}